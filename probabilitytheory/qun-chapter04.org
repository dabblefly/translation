* 4 基本的假设检验
John Craig是一位苏格兰数学家，也是认识到Isaac Newton的新发明“微积分”优点的第一位学者之一。上述的句子，写于300多年前，是早期创造推理数学模型的尝试之一，其只需要改变一个字就可以描述我们现在的观点。我们认为我们的思想不是通过论辩而是被证据所驱动。如果容易犯错的人类并不总是能够达到这样的客观性，那么我们选择的愿景是为了在机器人中实现的。因此，看看我们机器人的思维是被新的证据“驱动到一个方向或是另一个方向”，我们研究了一些应用，虽然数学上简单，在几个不同的领域已被证明具有实际重要性。

从第一章列出的基本愿景来看，所有概率推论背后的基本原则是：

在抽样环境中（即当A代表一些数据集时），这个原则从一开始就显得很明显。我们在第3章中使用它，而不需要明确说明。但是，当我们转向更一般的情况时，这个原则需要强调，因为他对于所有的研究人员来说都不明显（我们将在后面的章节中多次看到）。

“诚实”或“客观”的本质要求我们考虑到我们拥有的所有证据，不仅仅是其被选择的任意一部分。任何这样的选择都将忽略我们所拥有的证据，或者假设我们没有证据。这使的我们开始认识到机器人总是可以获得一些信息。

** 4.1先验概率

一般来说，当我们给机器人的现有问题时，我们还会给出一些关于具体事项的新信息或“数据”D。但是，几乎机器人总是将有其他信息，我们暂时用X表示。这至少包括过去所有，从出厂时到接受现有问题时的经验。这总是可用信息的一部分，我们的愿景不允许机器人忽略它。如果我们人类把昨天所知道的东西丢弃后来推理我们今天的问题，我们将低于野生动物的水平；我们永远不可能知道有一天可以学到的东西，而且教育和文明将是不可能的。

所以对我们的机器人来说，没有“绝对”的概率这样的事情；所有的概率至少必须以X为条件。在解决问题时，根据原则（4.1），其推论应以P（A | DX）形式计算概率。通常，X的一部分与当前的问题无关，在这种情况下，它的存在是不必要而无害的；如果这是无关紧要的，它将在数学上被消掉。的确，这就是真正意义上的“不相干”。

任何以X为单独条件的概率P（A | X）称为先验概率。但是我们需要提醒的是，“先验”一词是另一个很早以前的术语之一，在今天可能是不恰当的和误导的。首先，它并不一定意味着“时间上的更早”。的确，时间的概念不在我们的一般理论中（虽然我们当然可以在特定的问题上介绍它）。这个区别是一个纯逻辑的区别；任何超出当前问题的即时数据D的其他信息，都要通过“先验信息”的定义。

例如，科学家已经不止一次地发生：当科学家收集了大量的数据，但在进行数据分析之前，他收到了一些令人惊讶的新信息，完全改变了他对如何分析数据的想法。令人惊讶的新信息在逻辑上是“先验信息”，因为它不是数据的一部分。确实，将总的证据分为两部分，分别称为这是我们作出的任意选择的“数据”和“先验信息”，只是为了方便组织一连串的推论。虽然所有这些组织必须导致相同的最终结果但是如果他们成功，可能得到的计算比其他更容易的。因此，我们确实需要考虑，在我们的计算中应考虑到不同信息的顺序。

由于过去曾经考虑过关于先验概率的一些奇怪事情，我们也指出，把X看作是一个隐藏的大前提或是一些关于自然的普遍有效的命题，是一个很大的错误。对于继续使用古代术语“先验概率”的人来说，关于先验概率的起源、性质和适当使用的旧误解仍然是常见的。康德（Immanuel Kant介绍了“先验”这个术语，表达了一个可以独立于经验知道真理的命题；最重要的是在这里我们不是那个意思。X仅表示超出我们所选择的“数据”之外机器人的任何附加信息。那些积极熟悉在现有实际问题中使用先验概率的人通常会进一步缩写，而不是说“先验概率”或“先验概率分布”，他们简单地说“先验”。

没有一个普遍的规则来分配先验-将语言先验信息转换为数值先验概率是一个开放式的逻辑分析问题，我们将多次返过来探讨该问题。目前，已知四个相当一般的原则-群不变性、最大熵、边际化和编码理论-使得许多不同类型的问题成功解决。毫无疑问，更多的原则正在等待被发现，这将开辟新的应用领域。

在常规的抽样理论中，唯一考虑的情况基本上是“从一个瓮中抓取”的情况，唯一出现的概率是预先假定“瓮”或“总体”的内容已经知道的概率，并寻求预测我们可能会得到什么“数据”。这类问题在细节上可能变得任意复杂，并且有一个高度发达的数学文献来处理它们。例如，Feller（1950，1966）的大部头的两卷作品和Kendall & Stuart（1977）的重量级概要，完全受限于抽样分布的计算。这些作品包含数百个非常重要的解决方案，在概率论的各个方面都是有用的，而此领域的每个研究人员都应该熟悉它们的可用性。


然而，如前一章所述，几乎所有真正的科学推理问题都涉及到我们所说的相反情况；我们已经知道了数据D，并且想要概率论来帮助我们决定“瓮”的可能内容。更一般地说，我们希望概率论可以来指出，根据数据和手头的其他证据，给定的一组假设{H1，H2，...}中的哪一个是最有可能的。例如，假设可能是关于生成数据的物理机制的各种假设。但从根本上说，与第三章一样，物理因果关系不是问题的基本要素；只有在假设和数据之间存在某种逻辑关系才是至关重要的。

为了解决这个问题，我们不需要超出我们用于发现条件抽样分布的积规则（3.1）的任何新原则，我们只需要对命题做出不同的选择。现在让我们用符号


同时将积准则写成

我们将P（D |HX）认为是第3章研究的抽样分布，但现在以更灵活的符号表示。在第3章中，我们不需要特别注意先前的信息X，因为所有的概率都是以H为条件的，因此我们可以隐含地假设定义了这个问题的一般口头上的先验信息被包括在了H中。这是我们已经习惯倾向于的符号，这掩盖了所有推论的统一性质。在所有的抽样理论中人们都可以逃避，并且结果是“先验信息”这个术语不在现有的抽样理论中。

然而现在，我们正在接近不是以H为条件的概率，但仍然以X为条件，所以我们需要为它们分别进行符号标记。从（4.2）可以看出，为了根据数据判断H的真实性，我们不仅需要抽样概率P（D|HX），还需要对D和H的先验概率：

虽然派生的（4.2）-（4.3）只是与（3.50）-（3.51）有相同的数学结果，对于许多研究者来说，二者似乎有不同的逻辑地位。从一开始，似乎清楚了如何确定抽样概率的值，但不能确定先验概率。在现在的工作中，我们将会看到，这只是一个不对称制定问题的方法，这给他们造成了不利影响。人们可以清楚地看出如何分配抽样概率，因为假设H被非常明确地表示；先验信息X被同样指定，如何分配先验概率会同样清楚。

当我们在一个充分根本的层面上看待这些问题，会意识到在我们有一个很好品问题之前，必须仔细地指定先前的信息，显然，（3.51）和（4.3）之间实际上没有逻辑上的差异；需要完全相同的原则来分配抽样概率或先验概率，而且一个人的抽样概率是另一个人的先验概率。

（4.3）的左侧，P（H | DX），通常被称为“后验概率”，伴有同样的警示，这意味着仅‘在被做出的特定推理链中在逻辑上稍后’，而不一定是“晚些时候”。再次区分是常规的，不是根本的；一个人的先验概率是另一个人的后验概率。这里实际上只有一种概率；我们对他们的不同称呼，仅仅指组织计算的一种特殊方式。

（4.3）中的最后一项也需要一个名称，称为似然L（H）。为了解释当前的使用情况，我们可以考虑固定假设及其对不同数据集的影响；正如我们前面已经指出的那样，P（D | HX）这个术语，它依赖于固定H上的D，被称为“抽样分布”。但是，我们可以根据各种不同的假设{H，H’，...}考虑固定数据集；在依赖于H的固定D中，P（D | HX）被称为“似然”。

似然L（H）本身不是H的概率；它是一个无量纲数值函数，当乘以先验概率和归一化因子时，可能成为概率。因此，不变因素是无关紧要的，可能会被揭开。因此，数量L（Hi）= y（D）P（D | Hi X）同样可以称为似然，其中y是可能取决于D但与假设{Hi}无关的任何正数。因此，方程（4.3）是我们尝试从数据中得出结论的广泛科学推论的基本原理。无论我们是否试图学习我们尝试从核磁共振数据中学习化学键的性质，临床资料中的药物的有效性，地震数据的地球内部结构，经济数据的需求弹性，还是从望远镜得到遥远星系数据的结构，（4.3）表明我们需要发现哪些可能性，以便看到所有证据证明了什么结论。如果P（H | DX）非常接近于一个（零），那么我们可以得出结论，H很可能是真（假的），并且相应地起作用。但是，如果P（H | DX）距离1/2不远，机器人会警告我们，现有证据不足以证明任何非常明确的结论，我们需要获得更多更好品证据。

** 4.2用二进数据检验二元假设

假设检验的最简单的重要问题是我们只有两个假设来检验，且只有两个可能的数据值。令人惊讶的是，这成为许多重要推论和决策问题的现实且有价值的模式 首先，让我们将（4.3）适用于这个二元例子。它给我们H是真的概率，但是我们可以很好地写出H是假的概率：

如果我们取两个方程的比例，

术语P（D | X）将会消掉。这可能看起来没有什么特别的优势，但是我们此时所有的数量，H是真实的概率与它是假的概率的比率，有一个术语名称。我们称之为命题H的“几率”。 所以，如果我们写做“给定D和X，H上的几率”，符号为

那么我们可以将（4.3）和（4.4）组合成如下形式：

H上的后验几率等于先前几率乘以无量纲因子，也称为似然比。几率是概率的严格单调函数，所以我们可以同样很好地计算这个数量1。

在许多应用中，取对数是很方便的，因为我们便可以使得项相加。现在，我们以任何一个基数取对数，这也给笔者带来一些麻烦。我们的分析表达式总是比以自然对数（基为e）的术语看起来更整洁。但是回到20世纪40年代和20世纪50年代，当这个理论首次被发现时，我们使用了10为基的对数，因为它们更容易在数字上找到；这四张图表将放在单独的一页上。找到一个自然对数是一个繁琐的过程，需要通过浏览大量表格的旧数据。

今天，归功于手动计算器，所有这些表都已经过时了，且任何人都可以找到十位自然对数，就像10为基的对数一样简单。因此，我们开始愉快地从更美学的自然对数来重写这一部分。但结果告诉我们，使用基数为10的对数还有另一个甚至更强的原因。我们的头脑完全适应于10为基的对数，而且基为10的对数给我们所有人有一个立即、清晰直观的意义。但是，我们只是不知道该怎么做出一个以自然对数来表达的结论，直到被翻译成10个为基的项。因此，我们不情愿地重新编写了这个讨论，回到了旧的、丑的传统10为基的对数。

我们定义一个新的函数，我们称之为给定D和X的假设H的证据：

这仍然是概率的单调函数。通过使用基为10并将因子10放在前面，我们现在以分贝（以下简称为db）来测量证据。给定D，假设H的证据等于先前的证据加上通过计算在下列最后一项中对数似然率提供的分贝数：

现在假设这个新的信息D实际上由几个不同的命题组成：

那么我们可以通过积规则的连续应用来扩大似然比：

但是在许多情况下，得到D2的概率并不受D1知识的影响：

然后，常规地说D1和D2是独立的。当然，我们应该说，机器人分配给他们的概率是独立的。将“独立性”的属性归因于命题或事件是一种语义上的混乱；这意味着，一般用语中，物理因果的独立性。我们这里关心的与逻辑独立性的质量非常不同。

要强调这一点，请注意，没有任何一种独立意味着另一种。两个事件实际上可能不独立（即影响另一个）;但对于尚未发现这一点的科学家来说，这个概率代表他的知识状态-决定了他能够做出的唯一推论-可能是独立的。另一方面，两个事件看上去可能是因果独立的关系，即任何一方面不会起因于另一方面（例如苹果收成和桃子收成）的因果关系；但是我们认为它们之间有逻辑上的联系，所以一个新信息会改变我们对另一个知识的了解。那么，对我们来说，他们的概率不是独立的。

一般来说，随着H和X代表的机器人知识状态的变化，以他们为条件的概率可能从独立变为相关，反之亦然；但事件的真实属性保持不变。那么，将相关和独立的性质赋予给事件的人，实际上就是要求机器人有心理行为的能力。我们必须警惕现实与对现实的知识状态之间混淆，我们称之为“思想投射谬误”。

我们正在做的不仅仅是学究式的吹毛求疵，我们现在将看到（方程（4.29））它具有非常真实的实质性结果。在第3章中，我们已经讨论了这些概率可能是独立的一些条件，与来自非常大的已知总体和抽样有关。在结束评论部分我们强调，瓮是否是影响因素的可能性取决于我们知不知道这几个瓮里的东西是相同的。在我们目前的问题中，如第3章所述，将因果独立性解释为逻辑独立，或将逻辑相关解释为因果相关，导致了一些从心理学到量子理论领域无意义的结论。

如果给出（HX）和（），这几个数据在逻辑上是独立的，则（4.11）变为

其总和是我们获得的所有额外信息。

为了对这个数值有一些感觉，我们来构建表4.1。我们有三个不同尺度可以用来测量合情度的程度：证据、似然率或概率；它们都是彼此单调的函数。0分贝（db）的证据对应于1的似然率或1/2的概率。现在，每个物理学家或电气工程师都知道3 db意味着2（几乎）的因子，10db是10的因子（正好）。所以如果我们以3 db或10的步长，我们可以非常容易地构建这个表。

从表4.1中可以看出，为什么以分贝提供证据是非常说服力的。当概率接近1或0时，我们的直觉就不行。0.999和0.9999的概率之间的差异对你来说意义重大吗？这对于作者当然不是。但是，与之伴随只有短短的一段时间之后，30分贝和40分贝的证据之间的区别对我们有明确的意义。现在我们的头脑自然地理解了一个尺度。这只是Weber–Fechner法则的另一个例子；直觉人类的感觉往往是刺激的对数函数。

巧合的是，（4.8）中的因素10是适当的。在原始的声学应用中，被引入了这样的一个1db的声音强度，该变化在心理上是关于我们耳朵可感知到的最小变化。只要有一点熟悉和一点反思，我们认为读者会同意，1分贝的变化是关于我们直觉感觉到的合情度的最小增量。没有人声称Weber–Fechner法则是所有人类感觉的精确规则，但它的一般用途和适用性是明确的；它几乎总是不是绝对的变化，而是在我们看到的一些刺激中更多的是相对变化。有关Gustav Theodor Fechner（1801-87）的生活和工作的叙述，有趣的可见Stigler（1986c）。

现在让我们将（4.13）应用到一个具体计算中，我们将把它描述为工业质量控制的一个问题（尽管它可以同样适用于一个化学分析难题、物理实验的解释、判断两个经济理论等）。按照Good (1950)的例子，为了阐明一些原则点。我们假设一些不是很现实的数字。让先验信息X由以下语句组成：

X≡我们有11台自动生产小部件的机器，这些机器被分别塞进11个箱子里。这个例子与开发小部件非常早期的一个阶段对应，因为10台机器产生的六分之一有缺陷。第11台机器更糟糕；它产生的三分之一有缺陷。每个机器的产出被收集在未标签的盒子中，并存储在仓库中。

我们选择一个框，并测试一些小部件，将它们分类为“好”或“坏”。我们的工作是判定我们是否是从坏机器中选择了一个盒子；也就是说，我们是接受这个批次还是拒绝它。

让我们把这个工作交给我们的机器人，看看它的表现。首先，它必须发现有关各种主张的先前证据。让

A≡我们选择了一个坏品批次（1/3有缺陷），

B≡我们选择了一个好品批次（1/6有缺陷）。

我们先验信息X的定性部分告诉我们只有两种可能性；所以在X产生的“逻辑环境”中，这些命题与否定有关：给定X，我们可以这样说

唯一的定量先验信息是，有11台机器和我们不知道哪一台制造了我们的批次，所以，通过无差异的原则，P(A|X)=1/11，和

因此，我们必然有e（B|X）=+10db。

显然，在这个问题上，与计算相关的X的唯一属性只是这些数字，即±10db。导致相同数量的任何其他类型的先前信息将使我们从这一点开始就是相同的数学问题。所以没有必要说我们只是在谈论一个有11台机器的问题，等等。可能只有一台机器，而且先验信息包括有关它的以前经验。

我们以11台机器来说明这个问题的原因是，迄今为止，我们只有一个原则-无差异原则-可以将原始信息转换为数值概率。由于Feller（1950）关于一台机器的一个著名声明，我们插句话，我们在第17章中考虑到了更多关于他所提问题的证据。对我们的机器人来说，有多少台机器是没有什么不同的；唯一重要的是错误批次的先验概率，而不管这些信息是怎样得到的2。

现在，我们从这个盒子里拿出一个小部件，并测试它是否有缺陷。如果我们拿出一个是坏品，那么对一个坏批次的证据会产生什么作用呢？那会给它增加

其中，P（Bad|AX）表示给定A获得坏的小部件的概率；这些是抽样概率，并且我们已经看到了如何计算它们。我们的程序非常像“从缸里抽出来”，如同第三章的一样，一次抽取中我们的数据D现在只包含一个二项选择:(好/坏）。分布P（D|HX）简化为

因此，如果我们在第一个抽取中发现了一个坏的小部件，这将增加A的证据

如果我们抽取到第二个是坏品的话，现在会发生什么？我们正在进行没有放回的抽样，所以，正如我们在（3.11）中指出的，（4.19）中的因子（1/3）应该更新为
 
其中，N是该批次中的小部件数。但是，为了避免这种复杂性，我们假设N比我们考虑测试的任何数字大得多；即，我们将要测试这个可以忽略不计的批次，其中坏与好的比例在抽取中没有明显变化。那么，应用超几何分布的极限形式（3.22），称为二项分布（3.86）。因此，我们将考虑到，给定A或B，抽取坏小部件的概率在每次抽取时都是一样的，无论先前抽取了什么；所以我们抽取的每一个坏品都会提供+3分贝的证据支持假设A。

现在假设我们找到一个好品小部件。使用（4.14），我们得到A的证据

但是我们称它为-1db。再次，如果批次中的次数足够大，这将适用于任何抽取。如果我们检查了n个小部件，我们发现了坏品部件和好品部件，我们有坏品批次的证据将是

一旦我们设置了对数机制，你就会看到这是多么容易。机器人的心灵以非常简单直接的方式向“一个方向或另一个方向驶去”。

也许这个结果使我们深入了解为什么Weber–Fechner法则适用于直观可信的推论。我们的“证据”函数与我们在最自然的想象中观察到的数据有关；给定的证据增量与给定的数据增量相对应。例如，如果我们测试的第一个小部件产生了五个坏品，那么

或者，坏批次的概率由（1/11）=0.09的数据提高到。

为了获得至少20分贝关于命题A的证据，我们必须在n=nb+ng测试的某个顺序中找到多少个坏小部件？这需要

因此，如果坏的分数fb≡nb/n依然大于1/4，我们将获得20分贝或任何其他更多的证据。在该测试中，fb =1/4看起来是个阈值，不能提供有关A或B哪方更被支持的证据；但请注意，（4.22）中的+3和-1只是近似值。由（4.19）和（4.21）得，坏品的阈值分数为

其中对数的基对结果没有影响。抽样的分数大于（小于）该值表示支持A超过B（B超过A）的证据；但是如果观察到的分数接近该阈值，需要更多的测试来获得足够的证据。

无论你想叫它做什么，现在我们有的是，选择坏批次命题的概率、几率或证据。最终，我们必须作出决定：我们要接受它，否则我们会拒绝它。我们该怎么做？嗯，我们可能事先决定：如果命题A的概率达到一定水平，那么我们决定A是真的。如果它达到某个值，那么我们将决定A是假的。

概率论本身就没有告诉我们在作出决定是该如何确定这些关键点选取。这必须基于价值判断： 做出错误决定的后果是什么，进一步测试的成本是多少？这使我们引入了第13章和第14章所述的决策理论领域。但是现在很明显，出现一种错误（接受不好的批次）可能比做另一种错误（拒绝一个好的批次）会更严重。那就会对我们关键点的选取有一个明显的影响。

所以我们可以给机器人一些指示，如“如果A的证据更大超过+0分贝，那么拒绝这个批次（它更可能是坏的）。如果它低至-13分贝，然后接受它（至少有95％的概率是好的）。除此以外，继续测试”。我们开始做测试，并且每次我们发现一个坏的小部件的证据对于坏批次增加3分贝；每次我们找到一个好的，它会下降1分贝。测试一旦终止，我们进入第一次接受或拒绝状态。

如上所述，如果我们在命题A的后验概率达到一定水平的基础上告诉它拒绝或接受，我们的机器人将如何做。在统计文献中，这个非常有用和强大的程序称为“顺序推理”这个术语表示测试的次数并不是事先确定的，而是取决于我们发现的数据值序列；在每个步骤中，我们做出三个选择中的一个选择：（a）停止接受;（b）停止拒绝;（c）进行另一次测试。

这个术语不应该与所谓的“无停止选择的顺序分析”混淆，这是概率论的严重误用;见

第6章和第17章关于可停止的讨论。

** 4.3二元情况以外的不可扩展性

二元假设检验问题证明，有这样一个简单的解决方案，我们希望把它扩展到超过两个假设的情况。不幸的是，（4.13）中的数据集和（4.22）中数据集的独立可加性，不具有一般性。“独立可加性”的意思是，从给定数据Di给出的证据增量仅取决于Di和H;没有不取决于其他观察到的数据。如（4.11）所示，我们总是具有可加法，除非概率是独立的否则不是独立可加性。

我们以练习的形式为读者来说明这种不可扩展性的原因；为了做好准备，假设我们有n个假设{H1，...，Hn}，其在先验信息X中是相互排斥和可穷尽的：

此外，我们已经获得了m个数据集{D1，...，Dm}，并且因此Hi的概率以（4.7）的几率形式更新，现在变成了

由于Dj的逻辑独立性，分子的因式分解是很常见的，

如果分母也应该因式分解，

那么（4.27）将分成每个Dj独立生成的积，并且log-odds公式（4.9）将再次在Dj上采用如（4.13）形式的独立可加性。

在人工智能的文献中，这是一个有争议的问题（Glymour，1985; R.W.Johnson，1985）。那些不能区分逻辑独立性和因果独立性的人会假设（4.29）总是有效的，只要没有Di对任何其他Dj产生物理影响。但是，我们已经注意到这种推理的愚蠢；这是语义混乱可能导致严重数字错误的情形。当n=2时，（4.29）服从（4.28）。但是当n>2时，（4.29）是一个很强的条件，以致于它将整个问题缩减为不值得考虑的琐事;我们已经让读者来（练习4.1）检查方程看看为什么会这样。由于第2章阐述了Cox定理的拓展，概率理论的判断是，来回避我们关于非扩展性的结论，只能以我们推理中提出可证明不一致性作为代价。

为了消除对这里所说话的误解，我们再补充一下。无论我们考虑到多少假设，当然总是可以挑选出两个，并将它们相互比较。这就回到了已经分析的二元选择的情形，而且独立的可加性的属性在该较小的问题内依然保持（发现相对于单个替代方案的假设状态）。

我们可以通过选择A1作为标准的“零假设”来组织，并通过解决n-1个二元问题来比较其中的每一个；因此，任何两个命题的相对状态被确定。例如，如果A5和A7分别比A1高出22.3分贝和31.9分贝，那么A7比A5更高出31.9-22.3=9.6db。如果这样的二元假设的比较提供了所有需要的信息，那么就不需要考虑多个假设的检验。

但这不能解决我们现在的问题；给定所有这些二元假设问题的解决方案，它仍然需要像我们要做的那样大的计算，将该信息转换为相对于整个n类假设类别的任何给定假设的绝对状态。这里我们将直接解决更大的问题。

无论如何，我们不需要将立场仅仅放在一个抽象定理的专制性理论的主张上；更具建设性地，我们现在表明，概率论给了我们对一个关于多重假设检验的有效、确定的程序，这使我们有了更深入的了解，并且明确了为什么当n>2时，独立可加性不能也不应该成立。然后，它会忽略一些非常有力的信息；那是可证明的不一致性。

** 4.4多重假设检验

假设在刚刚讨论的顺序测试中发生了非常值得一提的事情：我们测试了50个小部件，每个小部件都证明是坏的。根据（4.22），这将给我们150分的证据，认为我们有不好的批次。e（A|E）最终将达到+140分贝，这是将单位一分为1014个部分的概率。现在，我们的常识拒绝这一结论；我们天生的某种怀疑在出现。如果你测试50个小部件，你发现所有的50个都是坏的，你不愿意相信你的这一批只有三分之一的是真的坏的。那么这里出了什么问题？为什么我们的机器人在这种情况下不工作？

我们必须认识到我们的机器人是不成熟的；它就像一个四岁的孩子一样。关于小孩子的惊人之处在于，你可以告诉他们最可笑的事情，他们会以睁大眼睛、嘴巴开张的方式接受，他们永远不会对你质疑。他们会相信你告诉他们的任何事情。

在告诉某些事情难以置信的时候，成年人学会为源头的可靠性做出精神上的宽恕。人们可能会认为，理想情况下，我们的机器人应该记录的信息不是我们有1/3坏或1/6坏;它应该提供的信息是，一些不可靠的人说我们有1/3坏或1/6坏。

更一般地说，如果机器人可以考虑到其给出的信息可能不是完全可靠的开始，那么在许多问题中可能是有用的。总有一种可能，我们给机器人的先验信息或数据是错误的。在一个现实问题中，总有数以百计的可能性，如果您开始使用教条初始语句的机器人，里面只有两种可能性，那么当然你不能指望其结论在每种情况下都有意义。

在机器人中自动完成怀疑成熟的行为是一件事情

为了在机器人中完成自动怀疑的成熟行为，当我们考虑显著性检验时，我们可以做到的。但幸运的是，在进一步的反应之后，我们意识到，对于大多数问题，目前的未成熟机器人是我们想要的，因为我们有更好的控制权。

我们确实想让机器人相信我们所说的话；当我们试图告诉它一些真实但让人吃惊的新事实时，让一个机器人在不受控制的情况下突然变得怀疑，是非常危险的。但是，我们现在明白这种情况，当有很好的时机需要机器人怀疑时，可以给我们的机器人一个关于对该特定问题如何持怀疑态度的提示。

在目前的问题中，当机器人看到“太多”坏的小部件时，我们可以通过提供一个可能的假设来给它一个怀疑命题A的提示。此时机器人将会注意到这个概率，因此实际上，机器人将置于被监视状态。像以前一样，让命题A表示我们有一个有1/3缺陷的盒子，命题B是我们有一个1/6缺陷盒子的声明。我们添加了第三个命题C，使得我们小部件机器出现完全错误，并且它出现了99％的缺陷。

现在，我们必须调整我们先验概率来考虑这个新的可能性。但我们不希望这是问题本质的重大变化。所以假设C具有非常低的先验概率P（C|X），10-6（-60db）。我们可以写出X包含这个意思的口头陈述，但是与前面的脚注一样，我们可以说X是什么，对于机器人的目的而言没有任何歧义，只是给出我们将在这个问题中所使用命题在X条件上的概率。这样我们就不会在概念上说明对我们重要的X的一切，但是我们说明与机器人当前数学问题相关的X的一切。所以，假定我们从以下三个初始概率开始：

其中
A我们有一个1/3缺陷的盒子
B我们有一个1/6缺陷的盒子
 C我们有一个1/99缺陷的盒子
因子几乎可以忽略不计，为了所有实际的目的，我们将从原始值的证据开始：

数据命题D代表“m个小部件被测试了并且每个都有缺陷”的声明。现在，由（4.9）得，命题C的后验证据等于先验证据加上这个概率比的对数的十倍：

我们在第3章中讨论放回和不放回抽样的结果表明

是给定99％机器的输出是坏的的情况下，前m个都是坏的概率，前提是箱子里的盒子总数比测试过的多。
我们还需要概率P（D|X），我们可以通过应用两次积准则（4.3）来估算：

在这个问题中，先验信息巧妙地表明，只有三个可能性，因此语句C≡“C是假的”意味着A或B必须有一个是真的：

在那里，我们使用一般的和规则（2.66），否定项由于A和B是相互排斥的而被消掉。类似的，

现在，如果我们将（4.36）替换为（4.35），则积规则将再次以此形式被应用

同时，（4.35）变为

其中，问题陈述中的所有概率是可知的。

*** 4.4.1另一派生词的解读

虽然我们有了理想的结果（4.39），但让我们注意另外一种推导方法，这通常比直接应用（4.3）更容易。该原则是在（3.33）的推导中引入的：将其希望得到概率的命题（在本例中为D）分解为相互排斥的命题，并计算其概率之和。我们可以通过“引入对话”任何一套相互排斥和可穷尽的命题（P，Q，R，...），并使用布尔代数规则，以许多不同的方式来执行这个决议：

但是，该方法的成功取决于我们在选择可以完成计算的特定集合时的巧妙性。这意味着所提出的命题必须与所问的问题有一种已知的相关性；如果这个问题与企鹅无关，则对第二章结尾的企鹅例子就不会有帮助。
在目前的情况下，对于P（D|X）的评估，似乎A和B命题有这样的相关性。再次，我们注意到命题C意味着（A + B）；所以

这些概率可以由积规则分为：

但是我们可以缩写：P（D | AX）≡P（D | AX）和P（D | BX）≡P（D | BX），因为在我们设置这个问题的方式中，A或B是真的声明意味着C必须是错。由于同样的原因，P（ | AX）= 1，因此，根据积规则，

对于P（B | CX）也是类似的。将这些结果代入（4.42）和使用（4.37），我们再次得到（4.39）。这一相同结果提供了我们扩展规则一致性的另一个例证，也是一个相当严峻的考验。
返回（4.39），我们有数值

（4.33）的一切都在现在。如果我们把所有这些东西放在一起，我们发现C命题的证据是

如果m>5，一个好的近似是

如果m<3，一个粗略的近似是

命题C以-60db开始，我们发现的第一个坏部件将分别给出约7.73分贝的证据支持命题C，所以，比较e（C | DX）与m的图，将以7.73的斜率向上。但是当m> 5时，斜率下降到4.73。当m≥49.6/ 4.73 = 10.5时，命题C的证据达到0db。所以，十个连续的坏部件足以将这个初始非常不可能的假设提高到58分贝，到达机器人准备好非常认真地考虑的地方；而11个连续的坏部件将会超过门槛，机器人认为它比虚假更可能是真实的。在此期间，我们的命题A和B发生了什么？如前所述，A以-10db开始，B以+10db开始，A的合理性开始以每个有缺陷部件上升3db。但是，在我们发现了太多的坏消息之后，怀疑论将会进入，你和我会开始怀疑证据是否真的支持命题A？命题C正在成为一个更容易的方式来解释观察到的内容。机器人有没有学会怀疑？
在这些小组件经过测试之后，一切都被证明是坏的，提出的A和B的证据以及大致的形式如下：



图4.1 令人惊奇的多次连续测试后，其中的死亡假说（C）被复活。

精确的结果总结在图4.1中。我们可以从研究这个图中学到很多关于多重假设检验的知识。A和B曲线的初始直线部分表示在我们引入命题C之前我们发现的解决方案；命题A和B的合理性的变化与以前的问题相同。命题C的效果不会出现，直到我们到达C跨过B的地方。在这一点上，A曲线的性质突然变化；而不是上升，在m = 7时，它已经达到了10db的最高值。然后转身回来；机器人确实已经学会了如何变得怀疑。但是B曲线在这一点上并没有改变，它直线地继续到达到A和C具有相同似然性的地方，并且在这一点上斜率有变化。从那时起，它就越来越快。
大多数人首先发现这一切令人惊奇和神秘的；但后来有一点中介就足以让我们察觉到发生了什么，为什么。由于我们现在正在针对两种替代方案（B和C）来测试假设A，因此，由于再次测试，A的似然性的变化来自于这样的事实。但是，最初，B比C更可信，因为在所有实际的目的下，我们只是简单地测试A对B，并再现我们以前的解决方案（4.22）。在有足够的证据累积以使C的可信度达到与B相同的水平之后，那么从那时起，A基本上是针对C而不是B进行测试，
这是一个非常不同的情况。所有这些斜率变化都可以这样解释。一旦我们看到这个原则，很明显，同样的事情将会更为普遍。只要我们有一组离散的假设，任何一个假设的合理性的变化将近似是对一个替代方案对这个假设进行测试的结果-单一的替代方案是最合理的剩余假设之一那时候。随着替代方案的相对可能性的变化，A曲线的斜率也必须改变;如果我们在n> 2时试图保留独立的添加剂形式（4.13），这将是遗漏的信息。
每当假设被分开大约10分贝或更多时，那么多个假设测试大约减少到针对单个替代方案测试每个假设。因此，看到这一点，您可以非常快速地构建图4.1所示的曲线，甚至不写下方程式，因为在两个假设情况下会发生什么，一劳永逸地看到。该图有许多其他有趣的几何属性，通过绘制六个渐近线并注意到它们的垂直对齐（虚线），我们留给读者探索。
构建相当准确的图表所需的所有信息都是由图4.2的“合理性流程图”所包含的，它总结了所有这些二进制问题的解决方案;一种可能的方式来测试一个命题对一个替代方案。它表明，例如，找到一个好的小部件提出了B的证据by1dbif B正在针对A进行测试，如果正在针对C进行测试，则为19.22分贝。类似地，如果A被测试B，但是如果A被针对B测试，则通过3db来证明A的证据，但是如果正在针对C进行测试，则将其降低4.73db。同样，我们看到，确定一个好的小部件可以将C的证据降低到两个坏的不可恢复的数量;所以有一个'怀疑的门槛'。 C将永远不会有明显的概率;即机器人永远不会对命题A和B产生怀疑，只要不良的部分f仍然小于2/3。

图4.2 合情度流程图
更准确地说，我们定义了一个阈值分数ft，因为f = mb / m→常数的测试m→∞的数量，e（C | DX）趋向于+∞iff> ft，并且为-∞iff确切的
阈值大于2/3：ft = 0.793951（练习4.2）。如果观察到的坏小部件仍然高于该值，则机器人最终将被引导为优于A和B上的命题C。



** 4.5连续概率分布函数

** 4.6检验有限数量的假设

*** 4.6.1岔开到历史话题

** 4.7简单和复杂（或复合）假设

** 4.8评论

*** 4.8.1词源

*** 4.8.2我们完成了什么？
